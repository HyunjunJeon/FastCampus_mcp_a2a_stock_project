# `src/mcp_servers/tavily_search_mcp` 코드 인덱스

Tavily AI 검색 API를 활용한 웹 검색 MCP 서버입니다. 실시간 웹 정보 수집, AI 기반 검색 결과 요약, 소셜 미디어 분석을 제공합니다.

## 📋 Breadcrumb

- 프로젝트 루트: [README.md](../../../README.md)
- 상위로: [mcp_servers](../code_index.md)
- 최상위: [src](../../code_index.md)
- **현재 위치**: `src/mcp_servers/tavily_search_mcp/` - 웹 검색 서버

## 🗂️ 하위 디렉토리 코드 인덱스

- (하위 디렉토리 없음)

## 📁 디렉토리 트리

```text
tavily_search_mcp/
├── __init__.py                      # 패키지 초기화
├── server.py                        # FastMCP 서버 구현
├── tavily_search_client.py          # Tavily API 클라이언트
└── code_index.md                    # 이 문서
```

## 📊 주요 컴포넌트

### 🎯 **server.py** - FastMCP 서버

#### 서버 초기화
```python
from fastmcp import FastMCP

mcp = FastMCP("tavily_search")
mcp.description = "AI-powered web search and content analysis"
```

#### 주요 도구 (Tools)

##### 1️⃣ **search_web** - 웹 검색
```python
@mcp.tool()
async def search_web(
    query: str,
    search_depth: str = "basic",  # basic, advanced
    max_results: int = 10,
    include_domains: Optional[List[str]] = None,
    exclude_domains: Optional[List[str]] = None,
    date_range: Optional[str] = None
) -> Dict[str, Any]:
    """AI 기반 웹 검색
    
    Returns:
        검색 결과 with AI 요약 및 관련성 점수
    """
```

##### 2️⃣ **search_finance_info** - 금융 정보 검색
```python
@mcp.tool()
async def search_finance_info(
    company: str,
    topics: List[str],
    language: str = "ko"
) -> Dict[str, Any]:
    """기업 금융 정보 검색
    
    Topics:
    - earnings: 실적 정보
    - news: 최신 뉴스
    - analysis: 애널리스트 의견
    - competitors: 경쟁사 정보
    - regulatory: 규제 관련
    """
```

##### 3️⃣ **search_social_sentiment** - 소셜 감성 분석
```python
@mcp.tool()
async def search_social_sentiment(
    keyword: str,
    platforms: List[str] = ["twitter", "reddit"],
    timeframe: str = "7d"
) -> Dict[str, Any]:
    """소셜 미디어 감성 분석
    
    Platforms:
    - Twitter/X
    - Reddit (r/stocks, r/investing)
    - StockTwits
    - YouTube comments
    """
```

##### 4️⃣ **get_topic_summary** - 주제 요약
```python
@mcp.tool()
async def get_topic_summary(
    topic: str,
    context: Optional[str] = None,
    detail_level: str = "medium"
) -> Dict[str, Any]:
    """특정 주제에 대한 종합 요약
    
    AI가 여러 소스를 분석하여
    통합된 인사이트 제공
    """
```

##### 5️⃣ **fact_check** - 팩트 체크
```python
@mcp.tool()
async def fact_check(
    statement: str,
    sources_required: int = 3
) -> Dict[str, Any]:
    """진술/정보 사실 확인
    
    Returns:
        - 사실 여부
        - 신뢰도 점수
        - 근거 출처
    """
```

### 🔌 **tavily_search_client.py** - Tavily 클라이언트

#### TavilySearchClient 클래스
```python
class TavilySearchClient:
    """Tavily AI Search API 클라이언트
    
    특징:
    - AI 기반 검색 결과 랭킹
    - 자동 콘텐츠 요약
    - 실시간 웹 크롤링
    - 구조화된 데이터 추출
    """
    
    def __init__(
        self,
        api_key: str,
        search_depth: str = "basic"
    ):
        self.api_key = api_key
        self.base_url = "https://api.tavily.com"
        self.session = aiohttp.ClientSession()
```

#### 핵심 메서드
```python
async def search(
    self,
    query: str,
    **kwargs
) -> Dict[str, Any]:
    """기본 검색 수행"""

async def search_with_context(
    self,
    query: str,
    context: str,
    **kwargs
) -> Dict[str, Any]:
    """컨텍스트 기반 검색"""

async def extract_content(
    self,
    urls: List[str]
) -> List[Dict[str, Any]]:
    """URL에서 콘텐츠 추출"""
```

## 🔍 검색 전략

### 검색 깊이 설정
```python
class SearchDepth(Enum):
    BASIC = "basic"        # 빠른 검색 (5-10 sources)
    ADVANCED = "advanced"  # 심층 검색 (20+ sources)
    RESEARCH = "research"  # 연구급 검색 (50+ sources)
```

### 도메인 필터링
```python
# 금융 정보 신뢰 도메인
FINANCE_DOMAINS = [
    "reuters.com",
    "bloomberg.com",
    "ft.com",
    "wsj.com",
    "cnbc.com",
    "marketwatch.com",
    # 한국
    "hankyung.com",
    "mk.co.kr",
    "sedaily.com"
]

# 제외 도메인
EXCLUDE_DOMAINS = [
    "pinterest.com",
    "facebook.com",
    "instagram.com"
]
```

## 🤖 AI 기능

### 자동 요약
```python
class ContentSummarizer:
    """AI 기반 콘텐츠 요약
    
    기능:
    - 핵심 포인트 추출
    - 불필요한 정보 제거
    - 구조화된 요약 생성
    """
    
    def summarize(
        self,
        content: str,
        max_length: int = 500
    ) -> str:
        """콘텐츠 요약"""
```

### 관련성 평가
```python
def calculate_relevance_score(
    result: Dict,
    query: str,
    context: Optional[str] = None
) -> float:
    """검색 결과 관련성 점수
    
    평가 기준:
    - 쿼리 매칭도
    - 콘텐츠 품질
    - 소스 신뢰도
    - 시간 관련성
    
    Returns:
        0.0 ~ 1.0 사이의 점수
    """
```

## 📊 데이터 구조

### 검색 결과 스키마
```python
@dataclass
class SearchResult:
    title: str                # 제목
    url: str                  # URL
    content: str              # 콘텐츠 요약
    score: float              # 관련성 점수
    published_date: datetime  # 발행일
    domain: str               # 도메인
    highlights: List[str]     # 핵심 문장
    raw_content: Optional[str] # 원본 콘텐츠
```

### 감성 분석 결과
```python
@dataclass
class SocialSentiment:
    platform: str             # 플랫폼
    keyword: str              # 검색 키워드
    sentiment_score: float    # -1.0 ~ 1.0
    volume: int               # 언급량
    trending: bool            # 트렌딩 여부
    top_posts: List[Dict]     # 주요 게시물
    word_cloud: Dict[str, int] # 단어 빈도
```

## 🚀 서버 실행

### 직접 실행
```bash
python -m src.mcp_servers.tavily_search_mcp.server
```

### 환경 변수 설정
```bash
export MCP_SEARCH_PORT=3020
export TAVILY_API_KEY=your-api-key
python -m src.mcp_servers.tavily_search_mcp.server
```

## 🔧 환경 변수

```bash
# 서버 설정
MCP_SEARCH_PORT=3020                 # 서버 포트
MCP_SEARCH_HOST=0.0.0.0             # 서버 호스트

# Tavily API
TAVILY_API_KEY=your-api-key          # Tavily API 키
TAVILY_SEARCH_DEPTH=basic            # 기본 검색 깊이
TAVILY_MAX_RESULTS=10                # 기본 결과 수

# 검색 설정
SEARCH_TIMEOUT=30                    # 검색 타임아웃 (초)
CACHE_ENABLED=true                   # 캐싱 활성화
CACHE_TTL=600                        # 캐시 TTL (10분)

# AI 설정
ENABLE_AI_SUMMARY=true               # AI 요약 활성화
SUMMARY_MAX_LENGTH=500               # 요약 최대 길이
RELEVANCE_THRESHOLD=0.5              # 관련성 임계값
```

## 📈 성능 메트릭

### 응답 시간
- **Basic 검색**: < 2초
- **Advanced 검색**: < 5초
- **Research 검색**: < 10초

### 품질 지표
- **관련성 정확도**: > 85%
- **요약 품질**: > 4.0/5.0
- **팩트 체크 정확도**: > 90%

## 🔍 사용 예시

### 금융 정보 검색
```python
# API 호출
response = await client.call_tool(
    "search_finance_info",
    {
        "company": "Tesla",
        "topics": ["earnings", "production"],
        "language": "ko"
    }
)

# 응답 예시
{
    "results": [
        {
            "title": "테슬라 4분기 실적 발표",
            "url": "https://...",
            "content": "테슬라가 4분기...",
            "score": 0.92,
            "highlights": [
                "매출 25% 증가",
                "생산량 목표 달성"
            ]
        }
    ],
    "summary": "테슬라는 4분기에...",
    "key_insights": [
        "생산 효율성 개선",
        "중국 시장 성장"
    ]
}
```

### 소셜 감성 분석
```python
# API 호출
response = await client.call_tool(
    "search_social_sentiment",
    {
        "keyword": "NVDA",
        "platforms": ["twitter", "reddit"],
        "timeframe": "7d"
    }
)

# 응답 예시
{
    "overall_sentiment": 0.72,
    "platform_breakdown": {
        "twitter": {
            "sentiment": 0.68,
            "volume": 15234,
            "trending": true
        },
        "reddit": {
            "sentiment": 0.76,
            "volume": 892,
            "trending": false
        }
    },
    "top_topics": ["AI", "earnings", "GPU"],
    "sentiment_trend": "increasing"
}
```

## 🧪 테스팅

### 유닛 테스트
```bash
pytest tests/mcp_servers/tavily_search_mcp/test_server.py
pytest tests/mcp_servers/tavily_search_mcp/test_client.py
```

### API 테스트
```bash
# 웹 검색 테스트
curl http://localhost:3020/tools/search_web \
  -d '{"query": "Samsung earnings 2024", "max_results": 5}'

# 감성 분석 테스트
curl http://localhost:3020/tools/search_social_sentiment \
  -d '{"keyword": "AAPL", "platforms": ["twitter"]}'
```

## 🔗 관련 문서

- [상위: MCP Servers](../code_index.md)
- [DataCollectorAgent](../../a2a_agents/data_collector/code_index.md)
- [Naver News MCP](../naver_news_mcp/code_index.md)
- [Tavily API 공식 문서](https://tavily.com/docs)